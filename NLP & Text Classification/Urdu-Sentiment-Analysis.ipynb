{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional,Dropout, SimpleRNN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.6.0-cp39-cp39-win_amd64.whl (12.3 MB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.11-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mannahil miftah\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: typing-extensions, colorama, catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 colorama-0.4.6 confection-0.1.0 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 pydantic-1.10.11 smart-open-6.3.0 spacy-3.6.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.9.0 typing-extensions-4.7.1 wasabi-1.1.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>اُس آدمی نے اِس سالار کو کافی معقول ٹپ دی ہے ۔</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>چچا غالب کی روح سے معذرت کے ساتھہم نے مانا کہ ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>واہ جناب واہ! اچھی رہی۔ جناب خود کو فرشتہ سمجو...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>اسلام آباد :پی اے ٹی کا دھرنا ختم، صفائی کے کا...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>دنیا نے کس کا راہ وفا میں دیا ہے ساتھتم بھی چل...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet Class\n",
       "0    میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1    چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                             ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3    سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4      ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P\n",
       "..                                                 ...   ...\n",
       "995     اُس آدمی نے اِس سالار کو کافی معقول ٹپ دی ہے ۔     P\n",
       "996  چچا غالب کی روح سے معذرت کے ساتھہم نے مانا کہ ...     P\n",
       "997  واہ جناب واہ! اچھی رہی۔ جناب خود کو فرشتہ سمجو...     P\n",
       "998  اسلام آباد :پی اے ٹی کا دھرنا ختم، صفائی کے کا...     P\n",
       "999  دنیا نے کس کا راہ وفا میں دیا ہے ساتھتم بھی چل...     P\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(r'C:\\Users\\Mannahil Miftah\\Downloads\\urdu-sentiment-corpus-v1.tsv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data into lists; Text and Labels\n",
    "\n",
    "d = r\"C:\\Users\\Mannahil Miftah\\Downloads\\urdu-sentiment-corpus-v1.tsv\"\n",
    "\n",
    "Text = []\n",
    "Label = []\n",
    "\n",
    "with open(d, 'r', encoding = 'utf-8') as file:\n",
    "    data_csv = csv.reader(file, delimiter = '\\t')\n",
    "    next(data_csv)\n",
    "\n",
    "    for row in data_csv:\n",
    "        # any row which doesnot contain either text, label or both will be skipped\n",
    "        if len(row) >= 2:\n",
    "            Text.append(row[0].strip())\n",
    "            Label.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary charactes from the text\n",
    "\n",
    "for i in range(len(Text)):\n",
    "    Text[i] = re.sub(r'[^\\w\\s]', '', Text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we have to do binary classification (P and N), so removing the text with label O\n",
    "\n",
    "text = []\n",
    "label = []\n",
    "for i in range(len(Text)):\n",
    "    if Label[i] == 'P' or Label[i] == 'N':\n",
    "        text.append(Text[i])\n",
    "        label.append(Label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  میں نے ایٹم بم بنایا ھے او بھائی ایٹم بمب کوٹ لکھپت والی اتفاق فیکٹری میں نہیں بنتاایٹم بم کہوٹہ کی ایٹمی\n",
      "Label:  P\n",
      "Text:  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن سکتے\n",
      "Label:  N\n",
      "Text:  سرچ انجن گوگل کے نائب صدر نے فضا میں  130000 فٹ کی بلندی پر چھلانگ لگا کر عالمی ریکارڈ قائم کرلیا چھلانگ کی\n",
      "Label:  P\n",
      "Text:  ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار أ\n",
      "Label:  P\n",
      "Text:  گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے هو تم جیالا هو اور جاهل نه هو یه ممکن نهیں \n",
      "Label:  N\n"
     ]
    }
   ],
   "source": [
    "# printing the data after cleaning\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"Text: \",text[i])\n",
    "    print(\"Label: \",label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the sequences to ensure that shorter sequences will have same length as the longest sequence or max length\n",
    "\n",
    "max_length = 200\n",
    "X_train = pad_sequences(X_train, maxlen = max_length, padding = 'post')\n",
    "X_test = pad_sequences(X_test, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = [2, 3]\n",
    "dropout_rates = [0.3, 0.7]\n",
    "rnn_result = []\n",
    "gru_result = []\n",
    "lstm_result = []\n",
    "bilstm_result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RNN model\n",
    "\n",
    "def rnn(layers, dropout_rate):\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(Embedding(input_dim = len(tokenizer.word_index) + 1, output_dim = 100, input_length = max_length))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model_rnn.add(SimpleRNN(units = 64, return_sequences = True))\n",
    "        model_rnn.add(Dropout(dropout_rate))\n",
    "\n",
    "    model_rnn.add(SimpleRNN(units = 64))\n",
    "    model_rnn.add(Dropout(dropout_rate))\n",
    "    model_rnn.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling and training the RNN model\n",
    "    model_rnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model_rnn.fit(X_train, y_train, epochs = 10, batch_size = 20, validation_data = (X_test, y_test))\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 5s 85ms/step - loss: 0.7339 - accuracy: 0.4905 - val_loss: 0.7234 - val_accuracy: 0.4735\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.7294 - accuracy: 0.5054 - val_loss: 0.7368 - val_accuracy: 0.4816\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.7242 - accuracy: 0.5191 - val_loss: 0.7375 - val_accuracy: 0.5061\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 0.7492 - accuracy: 0.4918 - val_loss: 0.6961 - val_accuracy: 0.4857\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 0.7359 - accuracy: 0.4782 - val_loss: 0.7129 - val_accuracy: 0.4939\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.7311 - accuracy: 0.5041 - val_loss: 0.6991 - val_accuracy: 0.4694\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.7332 - accuracy: 0.4877 - val_loss: 0.6941 - val_accuracy: 0.5306\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.7344 - accuracy: 0.4741 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.7160 - accuracy: 0.4946 - val_loss: 0.6988 - val_accuracy: 0.4857\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.7327 - accuracy: 0.4837 - val_loss: 0.7059 - val_accuracy: 0.4816\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 5s 99ms/step - loss: 0.8020 - accuracy: 0.5095 - val_loss: 0.7096 - val_accuracy: 0.4653\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 4s 97ms/step - loss: 0.8129 - accuracy: 0.4932 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 4s 101ms/step - loss: 0.7827 - accuracy: 0.4959 - val_loss: 0.6977 - val_accuracy: 0.5306\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.8000 - accuracy: 0.5027 - val_loss: 0.7097 - val_accuracy: 0.5388\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 3s 91ms/step - loss: 0.8164 - accuracy: 0.4986 - val_loss: 0.7260 - val_accuracy: 0.4898\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.8107 - accuracy: 0.5068 - val_loss: 0.6935 - val_accuracy: 0.4898\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.8090 - accuracy: 0.5095 - val_loss: 0.6952 - val_accuracy: 0.5184\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 3s 94ms/step - loss: 0.7982 - accuracy: 0.5123 - val_loss: 0.7000 - val_accuracy: 0.5429\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.7818 - accuracy: 0.5163 - val_loss: 0.6912 - val_accuracy: 0.5306\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.8040 - accuracy: 0.4673 - val_loss: 0.7049 - val_accuracy: 0.4735\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 6s 118ms/step - loss: 0.7795 - accuracy: 0.4986 - val_loss: 0.6993 - val_accuracy: 0.5143\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.7841 - accuracy: 0.4714 - val_loss: 0.7337 - val_accuracy: 0.5020\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 5s 147ms/step - loss: 0.7397 - accuracy: 0.5368 - val_loss: 0.7476 - val_accuracy: 0.4898\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.7910 - accuracy: 0.4619 - val_loss: 0.7145 - val_accuracy: 0.4612\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 5s 141ms/step - loss: 0.7574 - accuracy: 0.4741 - val_loss: 0.7187 - val_accuracy: 0.4776\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 5s 135ms/step - loss: 0.7447 - accuracy: 0.5109 - val_loss: 0.7135 - val_accuracy: 0.4571\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 6s 174ms/step - loss: 0.7367 - accuracy: 0.5054 - val_loss: 0.6946 - val_accuracy: 0.5469\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 5s 136ms/step - loss: 0.7590 - accuracy: 0.4809 - val_loss: 0.7252 - val_accuracy: 0.4776\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.7201 - accuracy: 0.5245 - val_loss: 0.7230 - val_accuracy: 0.4776\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 5s 132ms/step - loss: 0.7428 - accuracy: 0.4687 - val_loss: 0.7155 - val_accuracy: 0.4571\n",
      "8/8 [==============================] - 1s 32ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 7s 147ms/step - loss: 0.9304 - accuracy: 0.4973 - val_loss: 0.7135 - val_accuracy: 0.4694\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 5s 130ms/step - loss: 0.9122 - accuracy: 0.4850 - val_loss: 0.6914 - val_accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 5s 127ms/step - loss: 0.9477 - accuracy: 0.4605 - val_loss: 0.7282 - val_accuracy: 0.4694\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 5s 129ms/step - loss: 0.8710 - accuracy: 0.5123 - val_loss: 0.7019 - val_accuracy: 0.4694\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 5s 130ms/step - loss: 0.8690 - accuracy: 0.4905 - val_loss: 0.6969 - val_accuracy: 0.4694\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.7990 - accuracy: 0.5341 - val_loss: 0.6938 - val_accuracy: 0.4694\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 5s 140ms/step - loss: 0.7909 - accuracy: 0.5272 - val_loss: 0.6915 - val_accuracy: 0.5306\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 7s 188ms/step - loss: 0.7908 - accuracy: 0.4973 - val_loss: 0.6916 - val_accuracy: 0.5306\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.7854 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5306\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 5s 145ms/step - loss: 0.7981 - accuracy: 0.4809 - val_loss: 0.6917 - val_accuracy: 0.5306\n",
      "8/8 [==============================] - 1s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "for n in number_of_layers:\n",
    "    for d in dropout_rates:\n",
    "        model = rnn(n, d)\n",
    "        pred_rnn = np.round(model.predict(X_test))\n",
    "        accuracy_rnn = accuracy_score(y_test, pred_rnn)\n",
    "        precision_rnn = precision_score(y_test, pred_rnn, zero_division = 1)\n",
    "        recall_rnn = recall_score(y_test, pred_rnn)\n",
    "        f1_rnn = f1_score(y_test, pred_rnn)      \n",
    "        rnn_result.append({\n",
    "            'Number of layers':n,\n",
    "            'Dropout rate':d,\n",
    "            'Accuracy':accuracy_rnn,\n",
    "            'Precision':precision_rnn,\n",
    "            'Recall':recall_rnn,\n",
    "            'F1 score':f1_rnn\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.4816326530612245,\n",
       "  'Precision': 0.4423076923076923,\n",
       "  'Recall': 0.4,\n",
       "  'F1 score': 0.4200913242009133},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.47346938775510206,\n",
       "  'Precision': 0.4406779661016949,\n",
       "  'Recall': 0.45217391304347826,\n",
       "  'F1 score': 0.4463519313304721},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.45714285714285713,\n",
       "  'Precision': 0.41964285714285715,\n",
       "  'Recall': 0.40869565217391307,\n",
       "  'F1 score': 0.41409691629955947},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0}]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing results\n",
    "\n",
    "rnn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       130\n",
      "           1       0.00      0.00      0.00       115\n",
      "\n",
      "    accuracy                           0.53       245\n",
      "   macro avg       0.27      0.50      0.35       245\n",
      "weighted avg       0.28      0.53      0.37       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GRU model\n",
    "\n",
    "def gru(layers, dropout_rate):\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(Embedding(input_dim = len(tokenizer.word_index) + 1, output_dim = 100, input_length = max_length))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model_gru.add(GRU(units = 64, return_sequences = True))\n",
    "        model_gru.add(Dropout(dropout_rate))\n",
    "\n",
    "    model_gru.add(GRU(units = 64))\n",
    "    model_gru.add(Dropout(dropout_rate))\n",
    "    model_gru.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling and training the GRU model\n",
    "    model_gru.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model_gru.fit(X_train, y_train, epochs = 10, batch_size = 20, validation_data = (X_test, y_test))\n",
    "    return model_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 18s 265ms/step - loss: 0.6945 - accuracy: 0.5054 - val_loss: 0.6961 - val_accuracy: 0.4694\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.6958 - accuracy: 0.5068 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.6945 - accuracy: 0.4946 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 7s 200ms/step - loss: 0.6942 - accuracy: 0.4700 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 7s 192ms/step - loss: 0.6938 - accuracy: 0.4946 - val_loss: 0.6930 - val_accuracy: 0.5306\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 17s 471ms/step - loss: 0.6944 - accuracy: 0.4823 - val_loss: 0.6921 - val_accuracy: 0.5306\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 17s 467ms/step - loss: 0.6966 - accuracy: 0.4700 - val_loss: 0.6917 - val_accuracy: 0.5306\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 17s 453ms/step - loss: 0.6933 - accuracy: 0.5109 - val_loss: 0.6930 - val_accuracy: 0.5306\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 15s 395ms/step - loss: 0.6949 - accuracy: 0.4714 - val_loss: 0.6948 - val_accuracy: 0.4694\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 16s 436ms/step - loss: 0.6951 - accuracy: 0.5068 - val_loss: 0.6917 - val_accuracy: 0.5306\n",
      "8/8 [==============================] - 3s 140ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 25s 417ms/step - loss: 0.6962 - accuracy: 0.4837 - val_loss: 0.6938 - val_accuracy: 0.4694\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 7s 185ms/step - loss: 0.6930 - accuracy: 0.5109 - val_loss: 0.6942 - val_accuracy: 0.4694\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.6982 - accuracy: 0.4946 - val_loss: 0.6921 - val_accuracy: 0.5306\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.6974 - accuracy: 0.4918 - val_loss: 0.6935 - val_accuracy: 0.4694\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.6976 - accuracy: 0.4414 - val_loss: 0.6926 - val_accuracy: 0.5306\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 7s 179ms/step - loss: 0.6941 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5306\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 7s 187ms/step - loss: 0.6929 - accuracy: 0.5218 - val_loss: 0.6928 - val_accuracy: 0.5306\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 7s 194ms/step - loss: 0.7028 - accuracy: 0.4687 - val_loss: 0.6928 - val_accuracy: 0.5306\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 7s 191ms/step - loss: 0.6938 - accuracy: 0.4932 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 8s 217ms/step - loss: 0.6956 - accuracy: 0.4932 - val_loss: 0.6924 - val_accuracy: 0.5306\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 16s 289ms/step - loss: 0.6946 - accuracy: 0.5082 - val_loss: 0.6913 - val_accuracy: 0.5306\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.6982 - accuracy: 0.5082 - val_loss: 0.6926 - val_accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 10s 280ms/step - loss: 0.6930 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5306\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 12s 321ms/step - loss: 0.6946 - accuracy: 0.5027 - val_loss: 0.6928 - val_accuracy: 0.5306\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 27s 749ms/step - loss: 0.6935 - accuracy: 0.4973 - val_loss: 0.6940 - val_accuracy: 0.4694\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 24s 649ms/step - loss: 0.6951 - accuracy: 0.4959 - val_loss: 0.6934 - val_accuracy: 0.4694\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 23s 611ms/step - loss: 0.6952 - accuracy: 0.4605 - val_loss: 0.6948 - val_accuracy: 0.4694\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 23s 622ms/step - loss: 0.6950 - accuracy: 0.4728 - val_loss: 0.6931 - val_accuracy: 0.4694\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 23s 621ms/step - loss: 0.6936 - accuracy: 0.4823 - val_loss: 0.6924 - val_accuracy: 0.5306\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.6947 - accuracy: 0.4891 - val_loss: 0.6941 - val_accuracy: 0.4694\n",
      "8/8 [==============================] - 5s 211ms/step\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 24s 347ms/step - loss: 0.6937 - accuracy: 0.4755 - val_loss: 0.6915 - val_accuracy: 0.5306\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 15s 408ms/step - loss: 0.6961 - accuracy: 0.4986 - val_loss: 0.6928 - val_accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 24s 651ms/step - loss: 0.6951 - accuracy: 0.4782 - val_loss: 0.6933 - val_accuracy: 0.4694\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 26s 700ms/step - loss: 0.6945 - accuracy: 0.5286 - val_loss: 0.6930 - val_accuracy: 0.5306\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 24s 662ms/step - loss: 0.6976 - accuracy: 0.4877 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 24s 658ms/step - loss: 0.6948 - accuracy: 0.5259 - val_loss: 0.6955 - val_accuracy: 0.4694\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 24s 658ms/step - loss: 0.6962 - accuracy: 0.4959 - val_loss: 0.6925 - val_accuracy: 0.5306\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 24s 654ms/step - loss: 0.6965 - accuracy: 0.5136 - val_loss: 0.6950 - val_accuracy: 0.4694\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 22s 584ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5306\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 24s 637ms/step - loss: 0.6989 - accuracy: 0.4728 - val_loss: 0.6935 - val_accuracy: 0.4694\n",
      "8/8 [==============================] - 4s 224ms/step\n"
     ]
    }
   ],
   "source": [
    "for n in number_of_layers:\n",
    "    for d in dropout_rates:\n",
    "        model = gru(n, d)\n",
    "        pred_gru = np.round(model.predict(X_test))\n",
    "        accuracy_gru = accuracy_score(y_test, pred_gru)\n",
    "        precision_gru = precision_score(y_test, pred_gru, zero_division = 1)\n",
    "        recall_gru = recall_score(y_test, pred_gru)\n",
    "        f1_gru = f1_score(y_test, pred_gru)      \n",
    "        gru_result.append({\n",
    "            'Number of layers':n,\n",
    "            'Dropout rate':d,\n",
    "            'Accuracy':accuracy_gru,\n",
    "            'Precision':precision_gru,\n",
    "            'Recall':recall_gru,\n",
    "            'F1 score':f1_gru\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5061224489795918,\n",
       "  'Precision': 0.47368421052631576,\n",
       "  'Recall': 0.46956521739130436,\n",
       "  'F1 score': 0.47161572052401746},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5061224489795918,\n",
       "  'Precision': 0.47368421052631576,\n",
       "  'Recall': 0.46956521739130436,\n",
       "  'F1 score': 0.47161572052401746},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5061224489795918,\n",
       "  'Precision': 0.47368421052631576,\n",
       "  'Recall': 0.46956521739130436,\n",
       "  'F1 score': 0.47161572052401746},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5061224489795918,\n",
       "  'Precision': 0.47368421052631576,\n",
       "  'Recall': 0.46956521739130436,\n",
       "  'F1 score': 0.47161572052401746},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5142857142857142,\n",
       "  'Precision': 0.4830508474576271,\n",
       "  'Recall': 0.4956521739130435,\n",
       "  'F1 score': 0.4892703862660944},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.46938775510204084,\n",
       "  'Precision': 0.46938775510204084,\n",
       "  'Recall': 1.0,\n",
       "  'F1 score': 0.6388888888888888},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.46938775510204084,\n",
       "  'Precision': 0.46938775510204084,\n",
       "  'Recall': 1.0,\n",
       "  'F1 score': 0.6388888888888888},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.46938775510204084,\n",
       "  'Precision': 0.46938775510204084,\n",
       "  'Recall': 1.0,\n",
       "  'F1 score': 0.6388888888888888}]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing results\n",
    "\n",
    "gru_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       130\n",
      "           1       0.47      1.00      0.64       115\n",
      "\n",
      "    accuracy                           0.47       245\n",
      "   macro avg       0.23      0.50      0.32       245\n",
      "weighted avg       0.22      0.47      0.30       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_gru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining LSTM model\n",
    "\n",
    "def lstm(layers, dropout_rate):\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim = len(tokenizer.word_index) + 1, output_dim = 100, input_length = max_length))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model_lstm.add(LSTM(units = 64, return_sequences = True))\n",
    "        model_lstm.add(Dropout(dropout_rate))\n",
    "\n",
    "    model_lstm.add(LSTM(units = 64))\n",
    "    model_lstm.add(Dropout(dropout_rate))\n",
    "    model_lstm.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    # compiling and training the LSTM model\n",
    "    model_lstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model_lstm.fit(X_train, y_train, epochs = 10, batch_size = 20, validation_data = (X_test, y_test), verbose = 0)\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 93ms/step\n",
      "8/8 [==============================] - 1s 68ms/step\n",
      "8/8 [==============================] - 2s 126ms/step\n",
      "8/8 [==============================] - 3s 173ms/step\n"
     ]
    }
   ],
   "source": [
    "for n in number_of_layers:\n",
    "    for d in dropout_rates:\n",
    "        model = lstm(n, d)\n",
    "        pred_lstm = np.round(model.predict(X_test))\n",
    "        accuracy_lstm = accuracy_score(y_test, pred_lstm)\n",
    "        precision_lstm = precision_score(y_test, pred_lstm, zero_division = 1)\n",
    "        recall_lstm = recall_score(y_test, pred_lstm)\n",
    "        f1_lstm = f1_score(y_test, pred_lstm)      \n",
    "        lstm_result.append({\n",
    "            'Number of layers':n,\n",
    "            'Dropout rate':d,\n",
    "            'Accuracy':accuracy_lstm,\n",
    "            'Precision':precision_lstm,\n",
    "            'Recall':recall_lstm,\n",
    "            'F1 score':f1_lstm\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.46938775510204084,\n",
       "  'Precision': 0.46938775510204084,\n",
       "  'Recall': 1.0,\n",
       "  'F1 score': 0.6388888888888888},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.46938775510204084,\n",
       "  'Precision': 0.46938775510204084,\n",
       "  'Recall': 1.0,\n",
       "  'F1 score': 0.6388888888888888},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.5306122448979592,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1 score': 0.0}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the results\n",
    "\n",
    "lstm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       130\n",
      "           1       0.00      0.00      0.00       115\n",
      "\n",
      "    accuracy                           0.53       245\n",
      "   macro avg       0.27      0.50      0.35       245\n",
      "weighted avg       0.28      0.53      0.37       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mannahil Miftah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BILSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining BiLSTM model\n",
    "\n",
    "def bilstm(layers, dropout_rate):\n",
    "    model_bilstm = Sequential()\n",
    "    model_bilstm.add(Embedding(input_dim = len(tokenizer.word_index) + 1, output_dim = 100, input_length = max_length))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model_bilstm.add(Bidirectional(LSTM(units = 64, return_sequences = True)))\n",
    "        model_bilstm.add(Dropout(dropout_rate))\n",
    "\n",
    "    model_bilstm.add(Bidirectional(LSTM(units = 64)))\n",
    "    model_bilstm.add(Dropout(dropout_rate))\n",
    "    model_bilstm.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    # compiling and training the BiLSTM model\n",
    "    model_bilstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model_bilstm.fit(X_train, y_train, epochs = 10, batch_size = 20, validation_data = (X_test, y_test), verbose = 0)\n",
    "    return model_bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 157ms/step\n",
      "8/8 [==============================] - 2s 160ms/step\n",
      "8/8 [==============================] - 3s 194ms/step\n",
      "8/8 [==============================] - 7s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "for n in number_of_layers:\n",
    "    for d in dropout_rates:\n",
    "        model = bilstm(n, d)\n",
    "        pred_bilstm = np.round(model.predict(X_test))\n",
    "        accuracy_bilstm = accuracy_score(y_test, pred_bilstm)\n",
    "        precision_bilstm = precision_score(y_test, pred_bilstm, zero_division = 1)\n",
    "        recall_bilstm = recall_score(y_test, pred_bilstm)\n",
    "        f1_bilstm = f1_score(y_test, pred_bilstm)\n",
    "        bilstm_result.append({\n",
    "            'Number of layers':n,\n",
    "            'Dropout rate':d,\n",
    "            'Accuracy':accuracy_bilstm,\n",
    "            'Precision':precision_bilstm,\n",
    "            'Recall':recall_bilstm,\n",
    "            'F1 score':f1_bilstm\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Number of layers': 2,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.5836734693877551,\n",
       "  'Precision': 0.5355191256830601,\n",
       "  'Recall': 0.8521739130434782,\n",
       "  'F1 score': 0.6577181208053691},\n",
       " {'Number of layers': 2,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.6571428571428571,\n",
       "  'Precision': 0.624,\n",
       "  'Recall': 0.6782608695652174,\n",
       "  'F1 score': 0.65},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.3,\n",
       "  'Accuracy': 0.6163265306122448,\n",
       "  'Precision': 0.5755395683453237,\n",
       "  'Recall': 0.6956521739130435,\n",
       "  'F1 score': 0.6299212598425197},\n",
       " {'Number of layers': 3,\n",
       "  'Dropout rate': 0.7,\n",
       "  'Accuracy': 0.6204081632653061,\n",
       "  'Precision': 0.5859375,\n",
       "  'Recall': 0.6521739130434783,\n",
       "  'F1 score': 0.6172839506172839}]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the results\n",
    "\n",
    "bilstm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62       130\n",
      "           1       0.59      0.65      0.62       115\n",
      "\n",
      "    accuracy                           0.62       245\n",
      "   macro avg       0.62      0.62      0.62       245\n",
      "weighted avg       0.62      0.62      0.62       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_bilstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
